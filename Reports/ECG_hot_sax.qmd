---
title: "Identification of Heart disorders using Symbolic Aggregate Approximation (SAx)"
author: "Moses Owusu"
date: today
format: 
  html:
    embed-resources: true
    anchor-sections: false
    table-of-contents: true
execute:
  echo: false
---


# Load Data and format as list
```{r setup}
#| echo: true
#| warning: false
#| message: false

# load packages and data
#install.packages("devtools")
#install_github('jMotif/jmotif-R')
#install.packages("readxl")
#install.packages('readMat')

library(devtools)
library(jmotif)
library(readxl)
library(R.matlab)
library(plyr)
library(cvTools)
library(nloptr)
library(devtools)
library(jmotif)
library(readxl)
library(R.matlab)
library(pracma)    #for linspace
library(nloptr)

library(dplyr, warn.conflicts=FALSE)
library(janitor, warn.conflicts=FALSE)
library(lubridate, warn.conflicts=FALSE)
library(kableExtra, warn.conflicts=FALSE)
library(tidyr)
library(CIDAtools)
library(DT)
library(gt)
library(gtsummary)
library(ggplot2, warn.conflicts=FALSE)
theme_set(theme_bw())

#load data
trainData<-read.csv("/Users/owusum/Desktop/MKO/Identification-of-heart-disorders-using-Symbolic-Aggregate-Approximation/DataRaw/TRAIN.csv",header = FALSE)

## Important: Please convert these training data to a matrix. 
# remove first two columns which are class names and labels
mytraindata<-as.matrix(trainData[,-c(1,2)])

testData<-read.csv("/Users/owusum/Desktop/MKO/Identification-of-heart-disorders-using-Symbolic-Aggregate-Approximation/DataRaw/TEST.csv",header = FALSE)

mytestdata<-as.matrix(testData[,-c(1,2)])

#make data as list
my_list <- list(trainData[,2],mytraindata,testData[,2],mytestdata)
names(my_list) <- c("labels_train", "data_train","labels_test","data_test")
#str(my_list)

#attributes(my_list)
```


In my first two columns I have saved Class Name (NSR,APB,AFL,IVR $\dots$) and Class Labels (NSR==1,APB==2,AFL==3,IVR==4 4\dots$) of both training and test data with dimensions `r dim(mytraindata)` and `r dim(mytestdata)` respectively. The table below shows the classes and observations for each set.


\begin{table}[]
\begin{tabular}{|l|l|ll|}
\hline
\multirow{2}{*}{\textbf{Class}} & \multirow{2}{*}{\textbf{Label}} & \multicolumn{2}{l|}{\textbf{No of observations}}    \\ \cline{3-4} 
                                &                                 & \multicolumn{1}{l|}{\textbf{Train}} & \textbf{Test} \\ \hline
\textbf{NSR}                    & 1                               & \multicolumn{1}{l|}{175}            & 82            \\ \hline
\textbf{APB}                    & 2                               & \multicolumn{1}{l|}{20}             & 45            \\ \hline
\textbf{AFL}                    & 3                               & \multicolumn{1}{l|}{7}              & 30            \\ \hline
\textbf{AFIB}                   & 4                               & \multicolumn{1}{l|}{105}            & 30            \\ \hline
\textbf{SVTA}                   & 5                               & \multicolumn{1}{l|}{7}              & 6             \\ \hline
\textbf{PVC}                    & 6                               & \multicolumn{1}{l|}{86}             & 47            \\ \hline
\textbf{BIGENIMY}               & 7                               & \multicolumn{1}{l|}{49}             & 6             \\ \hline
\textbf{TRIGENIMY}              & 8                               & \multicolumn{1}{l|}{9}              & 4             \\ \hline
\textbf{VT}                     & 9                               & \multicolumn{1}{l|}{8}              & 1             \\ \hline
\textbf{FUSION}                 & 10                              & \multicolumn{1}{l|}{9}              & 2             \\ \hline
\textbf{LBBBB}                  & 11                              & \multicolumn{1}{l|}{88}             & 15            \\ \hline
\textbf{RBBBB}                  & 12                              & \multicolumn{1}{l|}{47}             & 15            \\ \hline
\textbf{Total}                  & -                               & \multicolumn{1}{l|}{610}            & 266           \\ \hline
\end{tabular}
\end{table}


# Set discretization parameters & convert to wordbags

Many series to wordbag yiels a dataframe of all words found in a class as well as the corresponding counts

```{r}
#| warning: false
#| message: false


# set the discretization parameters
w <-62 #60 # the sliding window size
p <- 31 #6  # the PAA size
a <- 6 #6  # the SAX alphabet size

# convert the train classes to wordbags (the dataset has 12 labels: 1, 2,..., 12)
nsr <- manyseries_to_wordbag(my_list[["data_train"]][my_list[["labels_train"]] == 1,], w, p, a, "exact", 0.01) 
apb <- manyseries_to_wordbag(my_list[["data_train"]][my_list[["labels_train"]] == 2,], w, p, a, "exact", 0.01) 
afl <- manyseries_to_wordbag(my_list[["data_train"]][my_list[["labels_train"]] == 3,], w, p, a, "exact", 0.01)
afib <- manyseries_to_wordbag(my_list[["data_train"]][my_list[["labels_train"]] == 4,], w, p, a, "exact", 0.01)
svta <- manyseries_to_wordbag(my_list[["data_train"]][my_list[["labels_train"]] == 5,], w, p, a, "exact", 0.01)
pvc <- manyseries_to_wordbag(my_list[["data_train"]][my_list[["labels_train"]] == 6,], w, p, a, "exact", 0.01)
bigenimy <- manyseries_to_wordbag(my_list[["data_train"]][my_list[["labels_train"]] == 7,], w, p, a, "exact", 0.01)
trigenimy <- manyseries_to_wordbag(my_list[["data_train"]][my_list[["labels_train"]] == 8,], w, p, a, "exact", 0.01)
vt <- manyseries_to_wordbag(my_list[["data_train"]][my_list[["labels_train"]] == 9,], w, p, a, "exact", 0.01)
fusion <- manyseries_to_wordbag(my_list[["data_train"]][my_list[["labels_train"]] == 10,], w, p, a, "exact", 0.01)
lbbbb <- manyseries_to_wordbag(my_list[["data_train"]][my_list[["labels_train"]] == 11,], w, p, a, "exact", 0.01)
rbbbb <- manyseries_to_wordbag(my_list[["data_train"]][my_list[["labels_train"]] == 12,], w, p, a, "exact", 0.01)
head(nsr)
```





# Compute TF*IDF weights for the bags

This yields a data frame: words which are "important" in TF*IDF terms (i.e. not presented at least in one of the bags) and their class-corresponding weights. Out of the dataframe for all classes, we can view words that are important to any particular class by arranging based on weight with `desc(class name)`

```{r}
tfidf = bags_to_tfidf( list("nsr" = nsr, "apb" = apb, "afl" = afl,"afib" = afib, "svta" = svta, "pvc" = pvc,
                              "bigenimy" = bigenimy, "trigenimy" = trigenimy, "vt" = vt, 
                              "fusion" = fusion, "lbbbb" = lbbbb,"rbbbb" = rbbbb) )

head(arrange(tfidf, desc(nsr)))
# head(arrange(tfidf, desc(apb)))
# head(arrange(tfidf, desc(afl)))
# head(arrange(tfidf, desc(svta)))
```


#SAX-VSM classification 

```{r}
# classify the test data
labels_predicted = rep(-1, length(my_list[["labels_test"]]))
labels_test = my_list[["labels_test"]]
data_test = my_list[["data_test"]]
for (i in c(1:length(data_test[,1]))) {
  series = data_test[i,]
  bag = series_to_wordbag(series, w, p, a, "exact", 0.01)
  cosines = cosine_sim(list("bag"= bag, "tfidf" = tfidf))
  labels_predicted[i] = which(cosines$cosines == max(cosines$cosines))
}
#labels_predicted # view predicted labesl
```




# Compute the classification error

```{r}
error = length(which((labels_test != labels_predicted))) / length(labels_test)
error
```


#findout which time series were misclassified
```{r}
which((labels_test != labels_predicted))
```
```{r}
par(mfrow=c(3,1))
plot(my_list[["data_test"]][28,], type="l")
plot(my_list[["data_test"]][118,], type="l")
plot(my_list[["data_test"]][233,], type="l")
```





##### Hot sax discord discovery



################ HOT-SAX FOR DISCORD DISCOVERY ################
?find_discords_brute_force
#arguments(ts, w_size, discords_num) discords_num is the number of discords to report
#install.packages("lineprof")
#library("profvis")
find_discords_brute_force(mytraindata[87,],62,2)

?find_discords_hotsax
# arguments (ts, w_size, paa_size, a_size, n_threshold, discords_num)
find_discords_hotsax(mytraindata[2,], 62, 31, 6, 0.01,1)


### FINDING MULTIPLE DISCORDS ####
discords = find_discords_hotsax(mytraindata[289,], 62, 31, 6, 0.01, 3)  #
discords

## SELECTING THE BEST DISCORD AND PLOT ##### the one with largest nn_distance
discords = find_discords_hotsax(mytraindata[289,], 62, 31, 6, 0.01, 3)
plot(mytraindata[289,], type = "l", col = "cornflowerblue", main = "ECG NSR ")
lines(x=c(discords[1,2]:(discords[1,2]+100)),
      y=mytraindata[289,][discords[1,2]:(discords[1,2]+100)], col="red")

discords = find_discords_hotsax(mytraindata[289,], 62, 31, 6, 0.01, 3)
plot(mytraindata[289,], type = "l", col = "cornflowerblue", main = "ECG NSR")
lines(x=c(discords[2,2]:(discords[2,2]+100)),
      y=mytraindata[289,][discords[2,2]:(discords[2,2]+100)], col="red")

discords = find_discords_hotsax(mytraindata[289,], 62, 31, 6, 0.01, 3)
plot(mytraindata[289,], type = "l", col = "cornflowerblue", main = "ECG NSR ")
lines(x=c(discords[3,2]:(discords[3,2]+50)),
      y=mytraindata[289,][discords[3,2]:(discords[3,2]+100)], col="red")

####################### mutli discord with plot#####
discords = find_discords_hotsax(mytraindata[544,], 62, 31, 6, 0.01, 3)
plot(mytraindata[544,], type = "l", col = "cornflowerblue", main = "ECG RBBBB - PATIENT 1 ")
lines(x=c(discords[1,2]:(discords[1,2]+100)),
      y= mytraindata[544,][discords[1,2]:(discords[1,2]+100)], col="red")
lines(x=c(discords[2,2]:(discords[2,2]+100)),
      y= mytraindata[544,][discords[2,2]:(discords[2,2]+100)], col="black")
lines(x=c(discords[3,2]:(discords[3,2]+100)),
      y= mytraindata[544,][discords[3,2]:(discords[3,2]+100)], col="lawngreen")


discords = find_discords_hotsax(mytraindata[583,], 62, 31, 6, 0.01, 3)
plot(mytraindata[583,], type = "l", col = "cornflowerblue", main = "ECG RBBBB - PATIENT 2")
lines(x=c(discords[1,2]:(discords[1,2]+100)),
      y= mytraindata[583,][discords[1,2]:(discords[1,2]+100)], col="red")
lines(x=c(discords[2,2]:(discords[2,2]+100)),
      y= mytraindata[583,][discords[2,2]:(discords[2,2]+100)], col="black")
lines(x=c(discords[3,2]:(discords[3,2]+100)),
      y= mytraindata[583,][discords[3,2]:(discords[3,2]+100)], col="lawngreen")


discords = find_discords_hotsax(mytraindata[601,], 62, 31, 6, 0.01, 3)
plot(mytraindata[601,], type = "l", col = "cornflowerblue", main = "ECG VT - PATIENT 3 ")
lines(x=c(discords[1,2]:(discords[1,2]+100)),
      y= mytraindata[601,][discords[1,2]:(discords[1,2]+100)], col="red")
lines(x=c(discords[2,2]:(discords[2,2]+100)),
      y= mytraindata[601,][discords[2,2]:(discords[2,2]+100)], col="black")
lines(x=c(discords[3,2]:(discords[3,2]+100)),
      y= mytraindata[601,][discords[3,2]:(discords[3,2]+100)], col="lawngreen")



#####SERIES TO CHARACTER STRING###


nsr_str<-series_to_string(mytraindata[127,],6) 
nsr_str<-series_to_string(paa (mytraindata[122,],p),6) 
nsr_str<-series_to_string(paa (mytraindata[120,],p),6) 
#nsr_char<-series_to_chars(paa (mytraindata[292,],p),5)
################trial end############



### SORT DISCORD BY NEAREST NEIGHBOUR DISTANCE #####
library(dplyr)
arrange(discords,desc(nn_distance))


###### ERROR BETWEEN CLASS COMPUTATION####
#LOAD DATA
##TRAIN
############################
trainData<-read.csv("TRAIN.csv",header = FALSE)
testData<-read.csv("TEST.csv",header = FALSE)
nsrAFL_train<-trainData[c(540:586, 279:453),] 
nsrapb_test<-testData[c(241:255,112:193),] #change row numbers for each disorder
mytraindata<-as.matrix(nsrapb_train[,-c(1,2)])
mytestdata<-as.matrix(nsrapb_test[,-c(1,2)])
dim(mytraindata) 
dim(mytestdata)
my_list <- list(nsrapb_train[,2],mytraindata,nsrapb_test[,2],mytestdata)
names(my_list) <- c("labels_trainM", "data_trainM","labels_testM","data_testM")
attributes(my_list)

############################
nsr_data <- my_list[["data_trainM"]][my_list[["labels_trainM"]] == 1,]
apb_data <-  my_list[["data_trainM"]][my_list[["labels_trainM"]] == 12,] #change the no for classes
#svta_data[,1:5] # view data


###TEST
#test_nsr  <- my_list[["data_testM"]][my_list[["labels_testM"]] == 1,]
#test_apb  <- my_list[["data_testM"]][my_list[["labels_testM"]] == 2,]


#SPECIFY PARAMETERS
w = 62
p = 31
a = 6

##CLASSES TO WORDBAGS
# convert the train classes to wordbags (the dataset has three labels: 1, 2, 3)
nsr <- manyseries_to_wordbag(my_list[["data_trainM"]][my_list[["labels_trainM"]] == 1,], w, p, a, "exact", 0.01)
apb <- manyseries_to_wordbag(my_list[["data_trainM"]][my_list[["labels_trainM"]] == 2,], w, p, a, "exact", 0.01) 



##TFIDF FOR CLASSES (2 EACH)####
#tfidf = bags_to_tfidf( list("nsr" = nsr, "apb" = apb, "afl" = afl, "afib" = afib, "svta" = svta, "pvc"= pvc,
#                            "bige" = bige, "trig" = trig, "vt"= vt, "fus"= fus,"lb"= lb, "rb"=rb) ) # for all
tfidf = bags_to_tfidf( list("nsr" = nsr, "apb" = apb) )  #REPLACE APB BY THE OTHER CLASSES


####WEIGHTED PATTERN PLOT####
# make up a sample time-series
sample = nsr_data[1,]
sample_bag = sax_via_window(sample, w, p, a, "exact", 0.01)
df = data.frame(index = as.numeric(names(sample_bag)), words = unlist(sample_bag))

# weight the found patterns
weighted_patterns = merge(df, tfidf)
specificity = rep(0, length(sample))
for(i in 1:length(weighted_patterns$words)){
  pattern = weighted_patterns[i,]
  for(j in 1:w){
    specificity[pattern$index+j] = specificity[pattern$index+j] +
      pattern$nsr - pattern$apb - pattern$afl - pattern$afib - pattern$svta - pattern$pvc - pattern$bige - pattern$trig - pattern$vt - pattern$fus - pattern$lb -pattern$rb
  }
}

# plot the weighted patterns
library(ggplot2)
library(scales)
ggplot(data=data.frame(x=c(1:length(sample)), y=sample, col=rescale(specificity)),
       aes(x=x,y=y,color=col)) + geom_line(size=1.2) + theme_bw() +
  ggtitle("WEIGHTED PATTERN PLOT") +
  scale_colour_gradientn(name = "Class specificity:  ",limits=c(0,1),
                         colours=c("red","yellow","green","lightblue","darkblue"),
                         breaks=c(0,0.5,1),labels=c("negative","neutral","high"),
                         guide = guide_colorbar(title.theme=element_text(size=14, angle=0),title.vjust=1,
                                                barheight=0.6, barwidth=6, label.theme=element_text(size=10, angle=0))) +
  theme(legend.position="bottom",plot.title=element_text(size=18),
        axis.title.x=element_blank(), axis.title.y=element_blank(),
        axis.text.x=element_text(size=12),axis.text.y=element_blank(),
        panel.grid.major.y = element_blank(), panel.grid.minor.y = element_blank(),
        axis.ticks.y = element_blank())


###CLASSIFY THE DATA 

labels_predicted = rep(-1, length(my_list[["labels_testM"]]))
labels_test = my_list[["labels_testM"]]
data_test = my_list[["data_testM"]]
for (i in c(1:length(data_test[,1]))) {
  series = data_test[i,]
  bag = series_to_wordbag(series, w, p, a, "exact", 0.01)
  cosines = cosine_sim(list("bag"=bag, "tfidf" = tfidf))
  labels_predicted[i] = which(cosines$cosines == max(cosines$cosines))
}

#compute the classification error
error = length(which((labels_test != labels_predicted))) / length(labels_test)
error

#findout which time series were misclassified
which((labels_test != labels_predicted))

#plot some misclassified time series
par(mfrow=c(3,1))
plot(my_list[["data_testM"]][1,], type="l")
plot(my_list[["data_testM"]][6,], type="l")
plot(my_list[["data_testM"]][12,], type="l")
#save.image("CBF_SAX.RData")


